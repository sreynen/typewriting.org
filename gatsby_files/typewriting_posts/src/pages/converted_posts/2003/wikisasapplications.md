---
path: "/2003/11/12/wikisasapplications" 
date: "2003/11/12 10:35:27" 
title: "wikis as applications" 
---
<p>the <a href="http://wiktionary.org/">wiktionary</a> is the dictionary form of the <a href="http://wikipedia.org/">wikipedia</a>. both are collaborative open content projects. i regularly use the wikipedia, and the wiktionary is promising, but just short of its potentional currently.</p><br><p>one thing missing from the wiktionary now is the important function of a dictionary in maintaining a complete set of known words. a dictionary not only provides definitions for existing words, but also provides a definitive list of which combinations of characters are words and which are not. if i search dictionary.com for a string of letters and no entries are found, i have a fairly good indication that string of letters isn't a word. but if i search wiktionary.org for the same string of letters and nothing comes up, i don't know if that's because it's not a word, or because no one has yet entered it. and of course the same problem exists with found words, as there's nothing stopping someone from entering definitions for words that don't exist. this incompleteness will likely be an ongoing problem for the wiktionary unless a conscious effort is made to fill in all the gaps.</p><br><p>making the wiktionary comprehensive isn't necessary to make it incredibly useful. it already does a great job of cross referencing words of different languages, making it a promising (though again, not complete) translation aid. also, if the wiktionary implemented some wiki markup specific to its task, such as standard means of marking things like synonyms, antonyms, other grammatical forms of the same root word, pronunciation, and so on, the wikipedia could be used as a huge data source for computational linguistics applications.</p><br><p>computational linguistics requires both a lexicon and a grammar, and the wiktionary could provide the first half with some minor tweeking. i had previously considered implementing the second half in some sort of distributed system wherein one site would define a sentence as (amount other things) a noun phrase followed by a verb phrase, and then point to other sites which would define what makes up noun phrases and verb phrases. it occurs to me now that this could all be stored in a central wiki, and cross-referenced with the wiktionary.</p><br><p>in other news of wiki applications, see <a href="http://www.wikiquote.org/">wikiquote</a>, which makes me question whether there is any further need for <a href="http://www.randomchaos.com/qml/">QML</a>. again, what is needed is standardization of format so that the data in this wiki can be reused and reformated. as it is, it's just a bunch of text.</p>